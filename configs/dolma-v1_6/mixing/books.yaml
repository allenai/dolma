
streams:
- name: books

  documents:
  - s3://ai2-llm/pretraining-data/sources/gutenberg/v0/documents/*.gz

  attributes:
  # - perplexity_suite_v3_option2
  - olmo_mix_v1_taggers
  - tokenizer_repetitions_v2r2

  output:
    path: s3://ai2-llm/pretraining-data/sources/olmo-mix/v1_5r2/documents/books
    max_size_in_bytes: 4294967296
    discard_fields:
    - attributes

  filter:
    exclude:
    - "$.attributes[?(@.olmo_mix_v1_taggers__uniseg_length_paragraphs_with_doc_length_v1__document[0][2]
      < 25)]"
    - "$.attributes[?(@.olmo_mix_v1_taggers__ft_lang_id_en_paragraph_with_doc_score_v2__doc_en[0][2]
      < 0.5)]"
    - "$.attributes[?(@.tokenizer_repetitions_v2r2__tokenizer_repetitions_v2r2__doc_max_score_repetition && @.tokenizer_repetitions_v2r2__tokenizer_repetitions_v2r2__doc_max_score_repetition[0] && @.tokenizer_repetitions_v2r2__tokenizer_repetitions_v2r2__doc_max_score_repetition[0][2] >= 100)]"

    # - "$@.attributes[?(@.bff_duplicate_paragraph_spans_decontamination && @.bff_duplicate_paragraph_spans_decontamination[0] && @.bff_duplicate_paragraph_spans_decontamination[0][2] >= 1.0)]"


work_dir:
  input: "/tmp/olmo-mix-v1_5/input"
  output: "/tmp/olmo-mix-v1_5/output"
processes: 188
